---
title: "ECON293_Final_Project"
output: pdf_document
date: '2022-05-25'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Role of Default in Probability of Tipping: An ML Approach

## Introduction

Our research question studies whether default tip suggestions for Uber rides in New York City change the probability of opting to leave no credit card tip when presented with the higher suggested amounts. We exploit a regression discontinuity design, which we will refer to as RDD, in the tip format, where before \$15 dollars, tips are shown as absolute amount, and after \$15 tips are presented in relative amounts. A previous paper has estimated this effect using the standard RDD methodology. Our contribution would be to use machine learning methods to improve the average treatment effect (ATE) estimations from the paper, and provide new heterogeneous treatment effects (HTE) estimations (e.g. how does the default tip effect change depending on the day of the ride).

## Data Cleaning

```{r, echo=FALSE, message=FALSE, warning=FALSE}
## Clear the data environment
rm(list = ls())

## Packages
list.of.packages <- c("tidyverse","dplyr","fastDummies","gtsummary","labelled","lmtest","sandwich","grf","glmnet","sandwich","splines","ggplot2","ggpubr","data.table","qwraps2","rpart","MASS","pracma","haven","estimatr","Matrix")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
for(pkg in list.of.packages){
  library(pkg, character.only = TRUE)
}
library(causalTree)
library(optrdd)
library(quadprog)

## File path 
user = Sys.info()[["user"]]
if (user == "51989"){ ## Bruno's PC path
  user = "51989/OneDrive/Escritorio"
}
In_Data <- paste0("/Users/", user, "/Dropbox/Default Tips Project/Data/Intermediate/")
Raw_Data <- paste0("/Users/", user, "/Dropbox/Default Tips Project/Data/Raw/")
Output <- "/Users/chenyuej/Dropbox/Default Tips Project/Output/"

## Today's date
Today <- format(Sys.Date(), "%d%m%Y")
```

```{r}

# Step 1: Cleaning -----

## Read in the stata version of the data
tips2009_clean <- read_dta(paste0(Raw_Data,"tips2009_clean.dta"))

## Subset the data according to the following rules:
## 1. Rides from the vendors only
## 2. Fare between 12 to 18 dollars 
tips2009_vendor_1218 <- tips2009_clean %>% filter(vendor == 1 & fare >= 12 & fare <= 18)

# Step 2: Create additional categorical variables for the covariates
classify_cov <- function(data){
  ## Categorize day of week 
  data2 <- data %>% 
    mutate(weekend = ifelse(pkp_dow >= 1 & pkp_dow <= 5, 0, 1))
  ## Categorize time of the day 
  data3 <- data2 %>%
    mutate(pickup_time_group = ifelse(pkp_hour >= 6 & pkp_hour <= 12, 1,
                                     ifelse(pkp_hour >= 13 & pkp_hour <= 16, 2, 
                                            ifelse(pkp_hour >= 17 & pkp_hour <= 20, 3, 0))))
  ## Convert the pick up locations to numeric, because the causal forest package does not support 
  ## non-numeric values 
  data4 <- data3 %>%
    mutate(Manhattan_pkp = ifelse(pkp_boro == "Manhattan", 1,0),
           Brooklyn_pkp = ifelse(pkp_boro == "Brooklyn", 1,0),
           Queens_pkp = ifelse(pkp_boro == "Queens", 1,0),
           Bronx_pkp = ifelse(pkp_boro == "The Bronx", 1,0),
           Staten_pkp = ifelse(pkp_boro == "Staten Island", 1,0),
           Other_pkp = ifelse(pkp_boro == "", 1,0))
  
  ## Convert the drop off locations to numeric   
  data5 <- data4 %>%
    mutate(Manhattan_drf = ifelse(drf_boro == "Manhattan", 1,0),
           Brooklyn_drf = ifelse(drf_boro == "Brooklyn", 1,0),
           Queens_drf = ifelse(drf_boro == "Queens", 1,0),
           Bronx_drf = ifelse(drf_boro == "The Bronx", 1,0),
           Staten_drf = ifelse(drf_boro == "Staten Island", 1,0),
           Other_drf = ifelse(drf_boro == "", 1,0))
  
  data_fnl <- data5
  return(data_fnl)
}

tips2009_1218_regroup <- classify_cov(tips2009_vendor_1218)

# Step 3: Save the data -----
write.csv(tips2009_1218_regroup,paste0(In_Data,"fare_1218_recoded.csv"))

```

## Methods

### X Learner

```{r}
# Step 1: Import the data -----
tips2009_1218 <- read.csv(paste0(In_Data,"fare_1218_recoded.csv"))

# Step 2: Applied X-learner to the 1020 data -----
data <- tips2009_1218
n <- nrow(tips2009_1218)
# Treatment: Whether the fare amount is above or below 15 dollars
treatment <- "dsc_15"
# Outcome: Whether someone tips 0. 1 for yes, 0 for no.
outcome <- "tip_zero"
# Additional covariates
covariates <- c("weekend", "pickup_time_group", "gr_inc10_All", "Manhattan_pkp", "Brooklyn_pkp",
                "Queens_pkp", "Bronx_pkp", "Staten_pkp", "Other_pkp", "Manhattan_drf", 
                "Brooklyn_drf", "Queens_drf", "Bronx_drf", "Staten_drf", "Other_drf")

# Split the data into training and testing
split1<- sample(c(rep(0, 0.7 * nrow(data)), rep(1, 0.3 * nrow(data))))
data.train <- data[split1 == 0,]
data.test <- data[split1 == 1,]

data.train <- data[split1 == 0,]
data.test <- data[split1 == 1,]

W_train <- data.train[,treatment]
Y_train <- data.train[,outcome]
X_train <- data.train[,covariates]

W_test <- data.test[,treatment]
Y_test <- data.test[,outcome]
X_test <- data.test[,covariates]

# Implement the x learner 
tf0 = regression_forest(X_train[W_train==0,], Y_train[W_train==0])
yhat0 = predict(tf0, X_train[W_train==1,])$predictions
xf1 = regression_forest(X_train[W_train==1,], Y_train[W_train==1]-yhat0)
xf.preds.1 = predict(xf1, X_test)$predictions
xf.preds.1[W_test==1] = predict(xf1,X_test[W_test==1,])$predictions
tf1 = regression_forest(X_train[W_train==1,], Y_train[W_train==1])
yhat1 = predict(tf1, X_train[W_train==0,])$predictions
xf0 = regression_forest(X_train[W_train==0,], yhat1-Y_train[W_train==0])
xf.preds.0 = predict(xf0, X_test)$predictions
xf.preds.0[W_test==0] = predict(xf0,X_test[W_test==0,])$predictions
propf = regression_forest(X_test, W_test)
ehat = predict(propf)$predictions

## Create a causal forest for plotting purposes.
cf.priority = causal_forest(X_train, Y_train, W_train)
priority.cate <- predict(cf.priority, X_test)$predictions

# Show the CATE distribution 
png(file=paste0(Output, "X_Learner_CATE.png"),width=595, height=545)
hist(ehat, main = "Distribution of CATEs, X Learner", xlab = "CATE")
dev.off()
```

### Causal Forest

```{r}

# Step 2: Applied X-learner to the 1020 data -----
data <- tips2009_1020
n <- nrow(tips2009_1020)
# Treatment: Whether the fare amount is above or below 15 dollars
treatment <- "dsc_15"
# Outcome: Whether someone tips 0. 1 for yes, 0 for no.
outcome <- "tip_zero"
# Additional covariates
covariates <- c("weekend", "pickup_time_group", "gr_inc10_All", "Manhattan_pkp", "Brooklyn_pkp",
                "Queens_pkp", "Bronx_pkp", "Staten_pkp", "Other_pkp", "Manhattan_drf", 
                "Brooklyn_drf", "Queens_drf", "Bronx_drf", "Staten_drf", "Other_drf")

# Split the data into training and testing
split1<- sample(c(rep(0, 0.7 * nrow(data)), rep(1, 0.3 * nrow(data))))
data.train <- data[split1 == 0,]
data.test <- data[split1 == 1,]

data.train <- data[split1 == 0,]
data.test <- data[split1 == 1,]

W_train <- data.train[,treatment]
Y_train <- data.train[,outcome]
X_train <- data.train[,covariates]

W_test <- data.test[,treatment]
Y_test <- data.test[,outcome]
X_test <- data.test[,covariates]

# Implement causal forest in grf
cf_model = causal_forest(
  X = X_train,
  Y = Y_train,
  W = W_train
)

# Estimate treatment effects on test data
cf_predict = predict(cf_model, X_test)

# Show the CATE distribution 
png(file=paste0(Output, "Causal_Forest_CATE.png"),width=595, height=545)
hist(cf_predict$predictions, main = "Distribution of CATEs, X Learner", xlab = "CATE")
dev.off()

```

### LM Forest

```{r}
data <- read.csv(paste0("/Users/", Sys.info()[["user"]], "/Dropbox/Default Tips Project/Data/Intermediate/fare_1217_recoded.csv"))

# Step 2: Applied X-learner to the 1020 data -----
n <- nrow(data)
# Treatment: Whether the fare amount is above or below 15 dollars
treatment <- "dsc_15"
# Outcome: Whether someone tips 0. 1 for yes, 0 for no.
outcome <- "tip_zero"
# Additional covariates
covariates <- c("weekend", "pickup_time_group", "gr_inc10_All", "Manhattan_pkp", "Brooklyn_pkp",
                "Queens_pkp", "Bronx_pkp", "Staten_pkp", "Other_pkp", "Manhattan_drf", 
                "Brooklyn_drf", "Queens_drf", "Bronx_drf", "Staten_drf", "Other_drf")

# Split the data into training and testing
split1<- sample(c(rep(0, 0.7 * nrow(data)), rep(1, 0.3 * nrow(data))))
data.train <- data[split1 == 0,]
data.test <- data[split1 == 1,]

data.train <- data[split1 == 0,]
data.test <- data[split1 == 1,]

W_train <- data.train[,treatment]
Y_train <- data.train[,outcome]
X_train <- data.train[,covariates]

W_test <- data.test[,treatment]
Y_test <- data.test[,outcome]
X_test <- data.test[,covariates]

# Implement causal forest in grf
lmf3 <- lm_forest(X_train, Y_train, W_train, num.trees = 250, seed = 42)

# Estimate treatment effects on test data
lm_forest_predict = predict(lmf3)$predictions

# Show the CATE distribution 
png(file=paste0(Output, "LM_Forest_CATE.png"),width=595, height=545)
hist(cf_predict$predictions, main = "Distribution of CATEs, LM Forest", xlab = "CATE")
dev.off()

```
